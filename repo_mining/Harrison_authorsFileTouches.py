import os
import json
from github import Github

# GitHub token (replace with your actual token during execution, but don't push the token to GitHub)
# last 3 = fQP
token = "ghp_5WBVAVT8IY8w08meSZ1HwBgIwuU28e2Ph"

# Repository to analyze
repo_name = "scottyab/rootbeer"

# Initialize GitHub API
g = Github(token)
repo = g.get_repo(repo_name)

# Path to the JSON file generated by Harrison_CollectFiles.py
file_touches_path = "data/file_rootbeer.json"

# Load the list of files and touch counts
if os.path.exists(file_touches_path):
    with open(file_touches_path, "r") as f:
        file_touches = json.load(f)
else:
    print(f"File not found: {file_touches_path}")
    exit()

# Dictionary to store authors and dates for each file
file_authors_data = {}

# Collect authors and commit dates for each file
for file_path in file_touches.keys():
    print(f"Processing file: {file_path}")
    file_authors_data[file_path] = []
    try:
        commits = repo.get_commits(path=file_path)
        for commit in commits:
            # Capture author and commit date
            author = commit.author.login if commit.author else "Unknown"
            commit_date = commit.commit.author.date.isoformat()
            file_authors_data[file_path].append({"author": author, "date": commit_date})
    except Exception as e:
        print(f"Error processing file {file_path}: {e}")

# Save the output to a JSON file
output_file = "data/file_authors.json"
with open(output_file, "w") as f:
    json.dump(file_authors_data, f, indent=4)

print(f"Author and date information saved to {output_file}")